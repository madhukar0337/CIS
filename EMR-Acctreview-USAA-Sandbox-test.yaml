#Version 2.2.4
#Updated by: Madhukar
#Changes from 2.2.2: Added emr-5.25.0
#Changes from 2.2.3: Added USAA Dedicated Sandbox configurations
Description: CloudFormation template for creating an EMR cluster
Outputs:
  IPAddress:
    Description: IP address of EMR cluster MasterNode
    Value: !GetAtt [rEMRCluster, MasterPublicDNS]
  ClusterURL:
    Description: Provides the URL of the Cluster
    Value: !Join ['', ['https://console.aws.amazon.com/elasticmapreduce/home?region=us-east-1#cluster-details:', !Ref 'rEMRCluster']]
Parameters:
  pEnvironment:
    Description: dev, stage, prod, qa, uat
    Type: String
    Default: prod
    AllowedValues:
      - dev
      - qa
      - stage
      - prod
  pExperianLANid:
    Description: User's Experian LAN ID
    AllowedPattern: "^[a-zA-Z0-9]*$"
    MinLength: 4
    MaxLength: 8
    Type: String
  pCoreInstanceCount:
    Default: '1'
    Description: Number of core instances
    Type: Number
    MinValue: 1
    MaxValue: 40
    ConstraintDescription: Number of core nodes should be within 1-40
  pMasterStorageVolume:
    Type: String
    Description: Additional Master Storage
  pCoreInstanceType:
    Default: m4.xlarge
    AllowedValues:
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.16xlarge
      - m5.4xlarge
      - m5.12xlarge
      - m5.24xlarge
      - r4.2xlarge
      - r4.4xlarge
      - r4.8xlarge
      - r4.16xlarge
      - p2.xlarge
      - p2.8xlarge
      - p2.16xlarge
    ConstraintDescription: Instance types that are allowed.
    Description: Instance Type of the core node
    Type: String
  pCoreStorageVolume:
    Default: 100
    AllowedValues:
      - 100
      - 200
      - 400
      - 600
      - 800
      - 1000
    ConstraintDescription: Attached storage to core nodes is limited
    Description: Code node storage volume attachment in GB
    Type: String
  pUseSpot:
    Default: true
    Description: true/false - if we should use spot
    AllowedValues:
      - true
      - false
    Type: String
  pTerminateCluster:
    Default: true
    Description: Should the cluster be terminated after use?
    AllowedValues:
      - true
    Type: String
#  pCoreBidPrice:
#    Default: 0.60
#    Description: Bid Price for Core instances if using Spot
#    Type: Number
#    MaxValue: 1.8
    ConstraintDescription: Bid price cannot exceed $1.8
  pEMRClusterName:
    Default: EMR-Acct-Review
    Description: Cluster name for the EMR
    Type: String
    AllowedValues:
      - EMR-Acct-Review
  pTeamTag:
    Description: The Tag name for the teams
    Type: String
    AllowedValues:
      - usaa-account-review
      - r8-devops
  pProject:
    Default: account-review
    Description: The Tag name for the projects
    Type: String
  pClient:
    Default: usaa
    Description: The Tag name for the Clients
    Type: String
  pApplication:
    Description: What applicaiton is this for
    Type: String
    AllowedValues:
      - dataload
      - automation
      - development
      - test
      - other
  pPurpose:
    Description: Reason for this EMR
    Type: String
  pEMRLogDir:
    Default: emrlogs
    Description: Log Dir for the EMR cluster
    Type: String
    AllowedValues:
      - emrlogs
  pKeyName:
    Default: Devscops
    Description: Name of an existing EC2 KeyPair to enable SSH to the instances
    Type: AWS::EC2::KeyPair::KeyName
  pMasterInstanceType:
    Default: m4.xlarge
    Description: Instance Type of the master node
    Type: String
    AllowedValues:
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.16xlarge
      - m5.4xlarge
      - m5.12xlarge
      - m5.24xlarge
      - r4.2xlarge
      - r4.4xlarge
      - r4.8xlarge
      - r4.16xlarge
      - p2.xlarge
      - p2.8xlarge
      - p2.16xlarge
#  pVPC:
#    Type: AWS::EC2::VPC::Id
#    Default: vpc-69a01110
#    Description: Select a VPC to deploy the Lambda function and EMR clusters
  pSubnet:
    Description: Subnet ID for creating the EMR cluster
    Default: subnet-006b8795f56729e6f
    Type: AWS::EC2::Subnet::Id
    AllowedValues:
      - subnet-0115e92807b410c02
      - subnet-0934b92f5dce241e7
      - subnet-006b8795f56729e6f
# pSquidProxyClientSG:
#   Description: Default EMR VPC
#    Default: sg-067b25d5ad701ef6c
#   Type: String
  pEmrReleaseLabel:
    Default: emr-5.16.0
    Description: Release label for the EMR cluster
    Type: String
    AllowedValues:
      - emr-5.25.0
      - emr-5.23.0
      - emr-5.22.0
      - emr-5.20.0
      - emr-5.18.0
      - emr-5.16.0
      - emr-5.15.0
      - emr-5.14.0
      - emr-5.13.0
      - emr-5.12.0
      - emr-5.11.0
      - emr-5.10.0
      - emr-5.8.0
      - emr-4.8.4
  pS3EMRBucketName:
    Default: expn-cis-account-review-sandbox-usaa
    Description: Bucket with the security configuration files
    Type: String
    AllowedValues:
      - expn-cis-account-review-sandbox-usaa
#  pS3CertsKey:
#    Default: automation/emr/certsnew.zip
#    Description: Bucket with the security configuration files
#    Type: String
#  pS3EMRBucket:
 #   Default: s3://cis-us-emr
  #  Description: Bucket with the step files
   # Type: String
  pS3BAPath:
    Default: admin/bootstrap/download-emr-steps.sh
    AllowedValues:
      - admin/bootstrap/download-emr-steps.sh
    Description: location for BA script
    Type: String
#  pS3PythonBootStrap:
#    Default: admin/bootstrap/download-python-modules.sh
#    AllowedValues:
#      - admin/bootstrap/download-python-modules.sh
#    Description: location for python modules download script
#    Type: String
  pS3StepsPath:
    Default: steps/emr-steps.json
    Description: location for steps json
    Type: String
    AllowedValues:
      - steps/emr-steps.json
#  pAdditionalSG:
#    Default: sg-eb728d98
#    Description: Additional SG to assign
#    Type: String
#  pSquidProxyPort:
#    Default: 3128
#    Description: Port for proxy
#    Type: String
#SquidProxyDNS
#  pDBPassword:
#    Default: r8EMRHive
#    Description: Hive metastore DB password
#    Type: String
#    NoEcho: true
#  pEMRSSHSg:
#    Default: sg-6b2daa1f
#    Description: Additional SG to assign
#    Type: String
#    AllowedValues:
#      - sg-6b2daa1f
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: "User Configuration"
        Parameters:
          - pEnvironment
          - pExperianLANid
          - pClient
          - pProject
          - pTeamTag
          - pApplication
          - pPurpose
      -
        Label:
          default: "EMR cluster configuration"
        Parameters:
          - pTerminateCluster
          - pMasterInstanceType
          - pCoreInstanceType
          - pEmrReleaseLabel
          - pUseSpot
#          - pCoreBidPrice
          - pUseSpot
          - pSubnet
          - pCoreInstanceCount
          - pMasterStorageVolume
          - pCoreStorageVolume
      -
        Label:
          default: "Defaults"
        Parameters:
          - pS3EMRBucketName
#          - pEMRSSHSg
#          - pKeyName
          - pEMRLogDir
          - pDBPassword
          - pEMRClusterName
          - pS3StepsPath
          - pS3BAPath
#          - pS3PythonBootStrap
#         - pSquidProxyDNS
#          - pSquidProxyPort
#          - pSquidProxyClientSG
    ParameterLabels:
      pEnvironment:
        default: "Environment"
      pExperianLANid:
        default: "Please specify your Experian LAN ID"
      pTerminateCluster:
        default: "Set this to true if you want the cluster to terminate"
      pMasterInstanceType:
        default: "Master Instance Type"
      pCoreInstanceType:
        default: "Core Instance Type"
      pSubnet:
        default: "Subnet"
      pEmrReleaseLabel:
        default: "EMR Release"
      pUseSpot:
        default: "Use Spot Instances"
      pEMRClusterName:
        default: "EMR Cluster Name"
      pCoreInstanceCount:
        default: "Number of Cores"
      pMasterStorageVolume:
        default: "Additional Master Storage"
      pCoreStorageVolume:
        default: "Additional Core Storage"
      pClient:
        default: "Client Name"
      pProject:
        default: "Project Name"
      pPurpose:
        default: "Purpose"
      pApplication:
        default: "Application"
      pTeamTag:
        default: "Team"
Mappings:
    Config:
        Hive:
            DevMetastorePassword: r8EMRHive
Conditions:
  UseSpot: !Equals [!Ref pUseSpot, true]
  DoNoTerminate: !Equals [!Ref pTerminateCluster, false]
  Terminate: !Equals [!Ref pTerminateCluster, true]
  OlderVersion: !Equals [!Ref pEmrReleaseLabel, 'emr-4.8.4']
Resources:
  CertsInfo:
    Type: Custom::CertsInfo
    Properties:
      ServiceToken: !GetAtt rSecurityConfigurationFunction.Arn
  PricingInfo:
    Type: Custom::PricingInfo
    Properties:
      ServiceToken: !GetAtt rPricingFunction.Arn
  pKMSLUKSKey:
    Properties:
      Description: Master Key that will be used for LUKS Encryption
      Enabled: 'true'
      KeyPolicy:
        Statement:
        - Action:
          - kms:Encrypt
          - kms:Decrypt
          - kms:GenerateDataKey
          Effect: Allow
          Principal:
            AWS:
            - !Join ['', ['arn:aws:iam::', !Ref 'AWS::AccountId', ':role/EMR_EC2_DefaultRole']]
          Resource:
          - '*'
          Sid: Stmt3
        - Action:
          - kms:Put*
          - kms:ScheduleKeyDeletion
          - kms:CancelKeyDeletion
          - kms:Describe*
          - kms:Revoke*
          - kms:Disable*
          - kms:Enable*
          - kms:Delete*
          - kms:List*
          - kms:Update*
          - kms:Create*
          Effect: Allow
          Principal:
            AWS:
            - !Join ['', ['arn:aws:iam::', !Ref 'AWS::AccountId', ':root']]
          Resource:
          - '*'
          Sid: Stmt4
        Version: '2012-10-17'
    Type: AWS::KMS::Key

  rLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
      - PolicyName: enicreateaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - ec2:CreateNetworkInterface
            - ec2:DescribeNetworkInterfaces
            - ec2:DeleteNetworkInterface
            Resource: '*'
      - PolicyName: lambdalogtocloudwatch
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
            Resource: arn:aws:logs:*:*:*
      - PolicyName: pricing-policy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - pricing:DescribeServices
            - pricing:GetAttributeValues
            - pricing:GetProducts
            Resource: '*'
      - PolicyName: s3listaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:ListBucket
            - s3:List*
            Resource:
              - arn:aws:s3:::expn-cis-account-review-sandbox-usaa/*
      - PolicyName: s3putaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            - s3:PutObject
            - s3:DeleteObject
            Resource:
              - arn:aws:s3:::expn-cis-account-review-sandbox-usaa/*
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaENIManagementAccess
  rLambdaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Lambda security group
      VpcId: vpc-0f25158d7f6cb7c74
      SecurityGroupEgress:
      - CidrIp: 0.0.0.0/0
        FromPort: '-1'
        IpProtocol: '-1'
        ToPort: '-1'
#  rCreateSecurityConfigurationFiles:
#    Type: Custom::LambdaCallout
#    DependsOn: rSecurityConfigurationFunction
#    Properties:
#      ServiceToken: !GetAtt [rSecurityConfigurationFunction, Arn]
#  rCreateSecurityConfigurationFiles:
#    Type: Custom::LambdaCallout
#    Version: "1.0"
#    DependsOn: rSecurityConfigurationFunction
#    Properties:
#      ServiceToken: !GetAtt 'rSecurityConfigurationFunction.Arn'
#      Region: !Ref "AWS::Region"
#            ServiceToken: !Sub |
#          arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${LambdaFunctionName}!GetAtt rSecurityConfigurationFunction.Arn
#    Type: "Custom::String"
#    Version: "1.0"
#    Properties:
#      ServiceToken: String
#        ... provider-defined properties ...
#  rEMRLambdaLogGroup:
#   Type: "AWS::Logs::LogGroup"
#   Properties:
#    LogGroupName: !Join ['', ['/aws/lambda/', !Ref rSecurityConfigurationFunction]]
#    RetentionInDays: 14

  rSecurityConfigurationFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          from __future__ import print_function
          import json
          import zipfile
          import boto3
          import os
          import subprocess
          import commands
          import cfnresponse
          import time
          def lambda_handler(event, context):
              s3_client = boto3.client('s3')
              s3_bucket = boto3.resource('s3').Bucket(os.environ['bucketname'])
              responseData = {}
              if event['RequestType'] == 'Delete':
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              else:
                s3_client.download_file(os.environ['bucketname'], 'admin/security/create-certs.sh', '/tmp/create-certs.sh')
                command_output = (commands.getstatusoutput('sh /tmp/create-certs.sh'))
                print("{}".format(command_output))
                if str(command_output).index("SUCCESS"):
                    timestamp = int(round(time.time() * 1000))
                    zf = zipfile.ZipFile("/tmp/certsnew.zip", "w")
                    for dirname, subdirs, files in os.walk("/tmp/certs"):
                      for filename in files:
                        if filename.endswith("pem"):
                          zf.write(os.path.join(dirname, filename), filename)
                    zf.close()
                    data = open('/tmp/certsnew.zip', 'rb')
                    key = "admin/certs/" + os.environ['pExperianLANid'] + "-" +  str(timestamp) + "-certs.zip"
                    s3_bucket.put_object(Body=data, ServerSideEncryption='AES256', Key=key)
                    responseData['certskey'] = key
                    cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
                return 'Completed with status {}'.format(responseData['certskey'])
      Handler: index.lambda_handler
      Environment:
        Variables:
          bucketname: !Ref pS3EMRBucketName
          pExperianLANid: !Ref pExperianLANid
      Runtime: python2.7
      Timeout: '30'
      Role:  !GetAtt [rLambdaExecutionRole, Arn]
  rPricingFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          from __future__ import print_function
          import json
          import decimal
          import boto3
          import os
          import pprint
          import cfnresponse
          def lambda_handler(event, context):
              pricing = boto3.client('pricing')
              response = pricing.get_products(ServiceCode='AmazonEC2',Filters = [{'Type' :'TERM_MATCH', 'Field':'instanceType', 'Value':os.environ['instanceType']},{'Type' :'TERM_MATCH', 'Field':'location','Value':'US East (N. Virginia)'},{'Type' :'TERM_MATCH', 'Field':'preInstalledSw','Value':'NA'}, {'Type' :'TERM_MATCH', 'Field':'tenancy',  'Value':'Shared'},{'Type' :'TERM_MATCH', 'Field':'operatingSystem',  'Value':'Linux'}, {'Type' :'TERM_MATCH', 'Field':'operation',  'Value':'RunInstances'}],MaxResults=100)
              price = response['PriceList'][0]
              data = json.loads(price)
              responseData = {}
              if event['RequestType'] == 'Delete':
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              else:
                response = pricing.get_products(ServiceCode='AmazonEC2',Filters = [{'Type' :'TERM_MATCH', 'Field':'instanceType', 'Value':os.environ['instanceType']},{'Type' :'TERM_MATCH', 'Field':'location','Value':'US East (N. Virginia)'},{'Type' :'TERM_MATCH', 'Field':'preInstalledSw','Value':'NA'}, {'Type' :'TERM_MATCH', 'Field':'tenancy',  'Value':'Shared'},{'Type' :'TERM_MATCH', 'Field':'operatingSystem',  'Value':'Linux'}, {'Type' :'TERM_MATCH', 'Field':'operation',  'Value':'RunInstances'}],MaxResults=100)
                price = response['PriceList'][0]
                data = json.loads(price)
                for key, value in data['terms']['OnDemand'].items():
                    rateCode = key+'.6YS6EN2CT7'
                    responseData['price'] = "{0:.3f}".format(decimal.Decimal(data['terms']['OnDemand'][key]['priceDimensions'][rateCode]['pricePerUnit']['USD']))
                    cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
                return 'Completed with status {}'.format(responseData['price'])
      Handler: index.lambda_handler
      Environment:
        Variables:
          instanceType: !Ref pCoreInstanceType
      Runtime: python2.7
      Timeout: '60'
      Role: !GetAtt [rLambdaExecutionRole, Arn]
  rSecurityConfiguration:
    DependsOn: CertsInfo
    Type: 'AWS::EMR::SecurityConfiguration'
    Properties:
      SecurityConfiguration:
        EncryptionConfiguration:
          EnableInTransitEncryption: true
          EnableAtRestEncryption: true
          InTransitEncryptionConfiguration:
            TLSCertificateConfiguration:
              CertificateProviderType: PEM
              S3Object: !Join ['', ['s3://', !Ref 'pS3EMRBucketName', '/', !GetAtt CertsInfo.certskey]]
          AtRestEncryptionConfiguration:
            S3EncryptionConfiguration:
              EncryptionMode: SSE-S3
            LocalDiskEncryptionConfiguration:
              EncryptionKeyProviderType: AwsKms
              AwsKmsKey: !GetAtt 'pKMSLUKSKey.Arn'
  rEMRCluster:
    Properties:
#      AdditionalInfo: {'instanceAwsClientConfiguration' : {'proxyPort' : !Ref 'pSquidProxyPort', 'proxyHost' : !Ref 'pSquidProxyDNS'} }
#     AdditionalInfo: {'instanceAwsClientConfiguration' : {'proxyPort' : '3128', 'proxyHost' : !Ref 'pSquidProxyDNS'} }
      SecurityConfiguration: !Ref rSecurityConfiguration
      Applications:
      - Name: Hive
      - Name: Spark
      - Name: Hue
      - Name: !If [OlderVersion, 'Oozie-Sandbox', 'Oozie']
      Configurations:
#      - Classification: hive-site
#        ConfigurationProperties:
#          javax.jdo.option.ConnectionURL:
#            Fn::Join:
#            - ''
#            - - jdbc:mysql://
#              - !ImportValue HiveMetastoreHost
#              - ":"
#              - !ImportValue HiveMetastorePort
#              - "/"
#              - hive?createDatabaseIfNotExist=true
#          javax.jdo.option.ConnectionUserName: !ImportValue HiveMetastoreDBUsername
#          javax.jdo.option.ConnectionPassword: !FindInMap [ Config, Hive, DevMetastorePassword ]
#        Configurations: []
#      - Classification: hadoop-env
#        Configurations:
#          - Classification: "export"
#            Configurations: []
#            ConfigurationProperties:
#              JAVA_HOME: /usr/lib/jvm/java-1.8.0
#              HADOOP_DATANODE_HEAPSIZE: 8192
      - Classification: spark-env
        Configurations:
          - Classification: "export"
            Configurations: []
            ConfigurationProperties:
              JAVA_HOME: /usr/lib/jvm/java-1.8.0
      - Classification: hadoop-kms-env
        Configurations:
          - Classification: "export"
            Configurations: []
            ConfigurationProperties:
              JAVA_HOME: /usr/lib/jvm/java-1.8.0
      - Classification: emrfs-site
        ConfigurationProperties:
          fs.s3.consistent: "true"
          fs.s3.consistent.metadata.read.capacity: "600"
          fs.s3.consistent.metadata.write.capacity: "300"
        Configurations: []
      BootstrapActions:
        - Name: DownloadScripts
          ScriptBootstrapAction:
            Args:
              - !Join ['', ['s3://', !Ref pS3EMRBucketName]]
              - us-east-1
              - !Join ['/', ['s3:/', !Ref pS3EMRBucketName, !Ref pExperianLANid, !Ref pS3StepsPath]]
            Path: !Join ['', ['s3://', !Ref pS3EMRBucketName, '/', !Ref pS3BAPath]]
#        - Name: DownloadPythonModules
#          ScriptBootstrapAction:
#            Args:
#              - us-east-1
#              - ip-172-16-0-48.ec2.internal
#              - 3128
#            Path: !Join ['', ['s3://', !Ref pS3EMRBucketName, '/', !Ref pS3PythonBootStrap]]
      Instances:
#       AdditionalMasterSecurityGroups:
#         - !Ref pSquidProxyClientSG
#          - !ImportValue SquidProxyClientSG
#          - !If [DoNoTerminate, !Ref 'pEMRSSHSg', !Ref 'AWS::NoValue']
#        AdditionalSlaveSecurityGroups:
#          - !Ref pSquidProxyClientSG
#          - !ImportValue SquidProxyClientSG
#          - !If [DoNoTerminate, !Ref 'pEMRSSHSg', !Ref 'AWS::NoValue']
        CoreInstanceGroup:
          EbsConfiguration:
            EbsBlockDeviceConfigs:
            - VolumeSpecification:
                SizeInGB: !Ref 'pCoreStorageVolume'
                VolumeType: gp2
              VolumesPerInstance: '1'
            EbsOptimized: 'true'
          InstanceCount: !Ref 'pCoreInstanceCount'
          InstanceType: !Ref 'pCoreInstanceType'
          Market: !If [UseSpot, SPOT, ON_DEMAND]
          BidPrice: !If [UseSpot, !GetAtt PricingInfo.price, !Ref 'AWS::NoValue']
          Name: Core Instance
#        Ec2KeyName: !If [DoNoTerminate, !Ref 'pKeyName', !Ref 'AWS::NoValue']
        Ec2SubnetId: !Ref pSubnet
        MasterInstanceGroup:
          InstanceCount: '1'
          InstanceType: !Ref 'pMasterInstanceType'
          EbsConfiguration:
            EbsBlockDeviceConfigs:
            - VolumeSpecification:
                SizeInGB: !Ref 'pMasterStorageVolume'
                VolumeType: gp2
            EbsOptimized: 'true'
          Market: ON_DEMAND
          Name: Master Instance
        TerminationProtected: 'false'
      JobFlowRole: EMR_EC2_DefaultRole
      LogUri: !Join ['/', ['s3:/', !Ref 'pS3EMRBucketName', !Ref 'pExperianLANid', !Ref 'pEMRLogDir']]
      Name: !Join ['', [!Ref 'pEMRClusterName', '-', !Ref 'pExperianLANid', !If [DoNoTerminate, '-no-terminate', '-auto-terminate']]]
      ReleaseLabel: !Ref 'pEmrReleaseLabel'
      ServiceRole: EMR_DefaultRole
      Tags:
      - Key: Name
        Value: !Join ['', ['EMR-Cluster-AR-', !Ref pEnvironment]]
      - Key: Team
        Value: !Ref 'pTeamTag'
      - Key: Client
        Value: !Ref 'pClient'
      - Key: Project
        Value: !Ref 'pProject'
      - Key: Environment
        Value: !Ref 'pEnvironment'
      - Key: Owner
        Value: !Ref 'pExperianLANid'
      - Key: Purpose
        Value: !Ref 'pPurpose'
      - Key: Application
        Value: !Ref 'pApplication'
      VisibleToAllUsers: 'true'
    Type: AWS::EMR::Cluster
#  SparkStep:
#    Properties:
#      ActionOnFailure: CONTINUE
#      HadoopJarStep:
#        Args:
#        - spark-submit
#        - --deploy-mode
#        - cluster
#        - --class
#        - org.apache.spark.examples.SparkPi
#        - /usr/lib/spark/examples/jars/spark-examples.jar
#        - '10'
#        Jar: command-runner.jar
#        MainClass: ''
#      JobFlowId: !Ref 'rEMRCluster'
#      Name: SparkStep
#    Type: AWS::EMR::Step
#  EMRSampleScriptRunner:
#    Properties:
#      ActionOnFailure: CONTINUE
#      HadoopJarStep:
#        Args:
#        - s3://cis-us-emr/admin/steps/emr-scipt-runner.sh
#        Jar: s3://cis-us-emr/admin/steps/script-runner.jar
#        MainClass: ''
#      JobFlowId: !Ref 'rEMRCluster'
#      Name: EMRSampleScriptRunner
#    Type: AWS::EMR::Step
#  DoNoTerminate:
#    Properties:
#      ActionOnFailure: CONTINUE
#      HadoopJarStep:
#        Args:
#        - aws
#        - emr
#        - terminate-clusters
#        - --cluster-ids
#        - !Ref rEMRCluster
#        Jar: command-runner.jar
#        MainClass: ''
#      JobFlowId: !Ref 'rEMRCluster'
#      Name: DoNoTerminate
#    Type: AWS::EMR::Step
  RunSteps:
    Condition: Terminate
    Properties:
      ActionOnFailure: CONTINUE
      HadoopJarStep:
        Args:
        - /tmp/emrsteps/update-emr-steps.sh
        - !Ref rEMRCluster
        - !Ref 'AWS::StackName'
#        - !Ref pSquidProxyDNS
        - 3128
        - us-east-1
        Jar: command-runner.jar
        MainClass: ''
      JobFlowId: !Ref 'rEMRCluster'
      Name: RunSteps
    Type: AWS::EMR::Step
