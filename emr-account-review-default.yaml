 #Author: Jerome Chadee
Description: CloudFormation template for creating an EMR cluster
Outputs:
  IPAddress:
    Description: IP address of EMR cluster MasterNode
    Value: !GetAtt [rEMRCluster, MasterPublicDNS]
  ClusterURL:
    Description: Provides the URL of the Cluster
    Value: !Join ['', ['https://console.aws.amazon.com/elasticmapreduce/home?region=us-east-1#cluster-details:', !Ref 'rEMRCluster']]
Parameters:
  pEnvironment:
    Description: dev, stage, prod, qa, uat
    Type: String
    Default: dev
    AllowedValues:
      - dev
      - qa
      - stage
      - uat
      - prod
      - poc
  pAmiID:
    Description: Custom AMI ID
    Type: String
    Default: ami-017a403ef1d9a2b86
  pExperianLANid:
    Description: User's Experian LAN ID
    AllowedPattern: "^[a-zA-Z0-9]*$"
    MinLength: 4
    MaxLength: 8
    Type: String
  pCoreInstanceCount:
    Default: '1'
    Description: Number of core instances
    Type: Number
    MinValue: 1
    MaxValue: 100
    ConstraintDescription: Number of core nodes should be within 1-100
  pCoreInstanceType:
    Default: m4.xlarge
    AllowedValues:
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.16xlarge
      - m5.4xlarge
      - m5.12xlarge
      - m5.24xlarge
      - r4.2xlarge
      - r4.4xlarge
      - r4.8xlarge
      - r4.16xlarge
    ConstraintDescription: Instance types should be one of the following m3.xlarge, m3.2xlarge, m4.2xlarge, m4.4xlarge, r4.2xlarge, r4.4xlarge
    Description: Instance Type of the core node
    Type: String
  pCoreStorageVolume:
    Default: 30
    AllowedValues:
      - 30
      - 50
      - 100
      - 200
      - 400
    ConstraintDescription: Attached storage to core nodes is limited
    Description: Code node storage volume attachment in GB
    Type: String
  pUseSpot:
    Default: true
    Description: true/false - if we should use spot
    AllowedValues:
      - true
      - false
    Type: String
  pTerminateCluster:
    Default: true
    Description: Should the cluster be terminated after use?
    AllowedValues:
      - true
      - false
    Type: String
#  pCoreBidPrice:
#    Default: 0.60
#    Description: Bid Price for Core instances if using Spot
#    Type: Number
#    MaxValue: 1.8
#    ConstraintDescription: Bid price cannot exceed $1.8
#  pEMRClusterName:
#    Default: EMR-ASCEND-PINNING
#    Description: Cluster name for the EMR
#    Type: String
#    AllowedValues:
#      - EMR-ASCEND-PINNING
  pTeamTag:
    Default: ascend-account-review
    Description: The Tag name for the teams
    Type: String
    AllowedValues:
      - ascend-pinning
      - ascend-map
      - ascend-devops
      - ascend-account-review
  pProject:
    Default: account-review
    Description: The Tag name for the projects
    Type: String
  pClient:
    Default: all
    Description: The Tag name for the Clients
    Type: String
    AllowedValues:
      - amex
      - barclays
      - bbva
      - bofa
      - chase
      - citi_brand
      - citi_retail
      - ir
      - omf
      - penfed
      - pnc
      - santander
      - sofi
      - synchrony
      - tiaa
      - usaa
      - usbank
      - wellsfargo
      - all
      - other
  pApplication:
    Description: What applicaiton is this for
    Default: account-review
    Type: String
  pPurpose:
    Description: Reason for this EMR
    Type: String
  pEMRLogDir:
    Default: emrlogs
    Description: Log Dir for the EMR cluster
    Type: String
    AllowedValues:
      - emrlogs
  pKeyName:
    Default: create-emr-dev
    Description: Name of an existing EC2 KeyPair to enable SSH to the instances
    Type: String
  pMasterInstanceType:
    Default: m4.xlarge
    Description: Instance Type of the master node
    Type: String
    AllowedValues:
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.10xlarge
      - m4.16xlarge
      - r4.2xlarge
      - r4.4xlarge
      - r4.8xlarge
      - r4.16xlarge
#  pVPC:
#    Type: AWS::EC2::VPC::Id
#    Default: vpc-69a01110
#    Description: Select a VPC to deploy the Lambda function and EMR clusters
  pSubnet:
    Description: Subnet ID for creating the EMR cluster
    Type: AWS::EC2::Subnet::Id
#    AllowedValues:
#      - subnet-002b750c
#      - subnet-45301f69
#      - subnet-9062caca
#  pSquidProxyClientSG:
#    Description: squid proxy client security group
#    Default: sg-eb728d98
#    Type: String
  pEmrReleaseLabel:
    Default: emr-5.17.0
    Description: Release label for the EMR cluster
    Type: String
    AllowedValues:
      - emr-5.21.0
      - emr-5.20.0
      - emr-5.19.0
      - emr-5.18.0
      - emr-5.17.0
      - emr-5.16.0
      - emr-5.15.0
      - emr-5.14.0
      - emr-5.13.0
      - emr-5.12.0
      - emr-5.11.0
      - emr-5.10.0
      - emr-5.8.0
      - emr-5.6.0
      - emr-5.0.0
      - emr-4.8.4
  pS3EMRBucketName:
    Default: expn-cis-account-review-dev-s3-emr
    Description: Bucket with the security configuration files
    Type: String
#  pS3CertsKey:
#    Default: automation/emr/certsnew.zip
#    Description: Bucket with the security configuration files
#    Type: String
#  pS3EMRBucket:
 #   Default: s3://r8-aws-emr
  #  Description: Bucket with the step files
   # Type: String
  pS3BAPath:
    Default: admin/bootstrap/download-emr-steps.sh
    AllowedValues:
      - admin/bootstrap/download-emr-steps.sh
    Description: location for BA script
    Type: String
  pS3StepsPath:
    Default: steps/emr-steps.json
    Description: location for steps json
    Type: String
    AllowedValues:
      - steps/emr-steps.json
#  pAdditionalSG:
#    Default: sg-eb728d98
#    Description: Additional SG to assign
#    Type: String
#  pSquidProxyPort:
#    Default: 3128
#    Description: Port for proxy
#    Type: String
#SquidProxyDNS
#  pSquidProxyHost:
#    Default: internal-R8SquidPr-ElasticL-1TZFAZP4N5KLU-1921049298.us-east-1.elb.amazonaws.com
#    Description: host for proxy
#    Type: String
#    AllowedValues:
#      - internal-squid-elb-1566798307.us-east-1.elb.amazonaws.com
#      - internal-R8SquidPr-ElasticL-1TZFAZP4N5KLU-1921049298.us-east-1.elb.amazonaws.com
#  pDBPassword:
#    Default: r8EMRHive
#    Description: Hive metastore DB password
#    Type: String
#    NoEcho: true
#  pEMRSSHSg:
#    Default: sg-59a81f28
#    Description: Additional SG to assign
#    Type: String
#    AllowedValues:
#      - sg-59a81f28
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: "User Configuration"
        Parameters:
          - pExperianLANid
          - pClient
          - pProject
          - pTeamTag
          - pApplication
          - pPurpose
      -
        Label:
          default: "EMR cluster configuration"
        Parameters:
#          - pTerminateCluster
          - pMasterInstanceType
          - pCoreInstanceType
          - pEmrReleaseLabel
          - pUseSpot
          - pSubnet
          - pCoreInstanceCount
          - pCoreStorageVolume
      -
        Label:
          default: "Defaults"
        Parameters:
          - pS3EMRBucketName
#          - pEMRSSHSg
#          - pKeyName
          - pEMRLogDir
          - pS3StepsPath
          - pS3BAPath
          - pDBPassword
#          - pS3PythonBootStrap
#          - pSquidProxyDNS
#          - pSquidProxyPort
#          - pSquidProxyClientSG
    ParameterLabels:
      pExperianLANid:
        default: "Experian LAN ID"
      pTerminateCluster:
        default: "Set this to true if you want the cluster to terminate"
      pMasterInstanceType:
        default: "Master Instance Type"
      pCoreInstanceType:
        default: "Core Instance Type"
      pSubnet:
        default: "Subnet"
      pEmrReleaseLabel:
        default: "EMR Release"
      pUseSpot:
        default: "Use Spot Instances"
      pCoreInstanceCount:
        default: "Number of Cores"
      pCoreStorageVolume:
        default: "Additional Core Storage"
      pClient:
        default: "Client Name"
      pProject:
        default: "Project Name"
      pPurpose:
        default: "Purpose"
      pApplication:
        default: "Application"
      pTeamTag:
        default: "Team"
Mappings:
    Config:
        Hive:
            DevMetastorePassword: r8EMRHive
Conditions:
  UseSpot: !Equals [!Ref pUseSpot, true]
  DoNoTerminate: !Equals [!Ref pTerminateCluster, false]
  Terminate: !Equals [!Ref pTerminateCluster, true]
  OlderVersion: !Equals [!Ref pEmrReleaseLabel, 'emr-4.8.4']
Resources:
  CertsInfo:
    Type: Custom::CertsInfo
    Properties:
      ServiceToken: !GetAtt rSecurityConfigurationFunction.Arn
  PricingInfo:
    Type: Custom::PricingInfo
    Properties:
      ServiceToken: !GetAtt rPricingFunction.Arn
  pKMSLUKSKey:
    Properties:
      Description: Master Key that will be used for LUKS Encryption
      Enabled: 'true'
      KeyPolicy:
        Statement:
        - Action:
          - kms:Encrypt
          - kms:Decrypt
          - kms:GenerateDataKey
          Effect: Allow
          Principal:
            AWS:
            - !Join ['', ['arn:aws:iam::', !Ref 'AWS::AccountId', ':role/EMR_EC2_DefaultRole', !Ref 'pClient' , !Ref 'pEnvironment']]
          Resource:
          - '*'
          Sid: Stmt3
        - Action:
          - kms:Put*
          - kms:ScheduleKeyDeletion
          - kms:CancelKeyDeletion
          - kms:Describe*
          - kms:Revoke*
          - kms:Disable*
          - kms:Enable*
          - kms:Delete*
          - kms:List*
          - kms:Update*
          - kms:Create*
          Effect: Allow
          Principal:
            AWS:
            - !Join ['', ['arn:aws:iam::', !Ref 'AWS::AccountId', ':root']]
          Resource:
          - '*'
          Sid: Stmt4
        Version: '2012-10-17'
    Type: AWS::KMS::Key

  rLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
      - PolicyName: enicreateaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - ec2:CreateNetworkInterface
            - ec2:DescribeNetworkInterfaces
            - ec2:DeleteNetworkInterface
            Resource: '*'
      - PolicyName: cloudformationaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - cloudformation:Describe*
            - cloudformation:Get*
            - cloudformation:List*
            - servicecatalog:Describe*
            Resource: '*'
      - PolicyName: servicecatalognaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - servicecatalog:Describe*
            Resource: '*'
      - PolicyName: ssmaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - ssm:Get*
            Resource: '*'
      - PolicyName: lambdalogtocloudwatch
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
#            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
            Resource: arn:aws:logs:*:*:*
      - PolicyName: pricing-policy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - pricing:DescribeServices
            - pricing:GetAttributeValues
            - pricing:GetProducts
            Resource: '*'
      - PolicyName: s3listaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:ListBucket
            - s3:List*
            Resource:
              - arn:aws:s3:::expn-cis-*-s3-emr/*
      - PolicyName: s3putaccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            - s3:PutObject
            - s3:DeleteObject
            Resource:
              - arn:aws:s3:::expn-cis-*-s3-emr/*
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaENIManagementAccess
  rLambdaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Lambda security group
      #!Join ['', ['EMRVPC', !Ref 'pClient', !Ref 'pEnvironment']]
      VpcId: !ImportValue
        'Fn::Sub': 'EMRVPC${pClient}${pEnvironment}'
      SecurityGroupEgress:
      - CidrIp: 0.0.0.0/0
        FromPort: '-1'
        IpProtocol: '-1'
        ToPort: '-1'
#  rCreateSecurityConfigurationFiles:
#    Type: Custom::LambdaCallout
#    DependsOn: rSecurityConfigurationFunction
#    Properties:
#      ServiceToken: !GetAtt [rSecurityConfigurationFunction, Arn]
#  rCreateSecurityConfigurationFiles:
#    Type: Custom::LambdaCallout
#    Version: "1.0"
#    DependsOn: rSecurityConfigurationFunction
#    Properties:
#      ServiceToken: !GetAtt 'rSecurityConfigurationFunction.Arn'
#      Region: !Ref "AWS::Region"
#            ServiceToken: !Sub |
#          arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${LambdaFunctionName}!GetAtt rSecurityConfigurationFunction.Arn
#    Type: "Custom::String"
#    Version: "1.0"
#    Properties:
#      ServiceToken: String
#        ... provider-defined properties ...
#  rEMRLambdaLogGroup:
#   Type: "AWS::Logs::LogGroup"
#   Properties:
#    LogGroupName: !Join ['', ['/aws/lambda/', !Ref rSecurityConfigurationFunction]]
#    RetentionInDays: 14
  rSecurityConfigurationFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          from __future__ import print_function
          import json
          import zipfile
          import boto3
          import os
          import subprocess
          import commands
          import cfnresponse
          import time
          def lambda_handler(event, context):
              s3_client = boto3.client('s3')
              s3_bucket = boto3.resource('s3').Bucket(os.environ['bucketname'])
              responseData = {}
              if event['RequestType'] == 'Delete':
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              else:
                s3_client.download_file(os.environ['bucketname'], 'admin/security/create-certs.sh', '/tmp/create-certs.sh')
                command_output = (commands.getstatusoutput('sh /tmp/create-certs.sh'))
                print("{}".format(command_output))
                if str(command_output).index("SUCCESS"):
                    timestamp = int(round(time.time() * 1000))
                    zf = zipfile.ZipFile("/tmp/certsnew.zip", "w")
                    for dirname, subdirs, files in os.walk("/tmp/certs"):
                      for filename in files:
                        if filename.endswith("pem"):
                          zf.write(os.path.join(dirname, filename), filename)
                    zf.close()
                    data = open('/tmp/certsnew.zip', 'rb')
                    key = "admin/certs/" + os.environ['pExperianLANid'] + "-" +  str(timestamp) + "-certs.zip"
                    s3_bucket.put_object(Body=data, ServerSideEncryption='AES256', Key=key)
                    responseData['certskey'] = key
                    cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
                return 'Completed with status {}'.format(responseData['certskey'])
      Handler: index.lambda_handler
      Environment:
        Variables:
          bucketname: !Ref pS3EMRBucketName
          pExperianLANid: !Ref pExperianLANid
      Runtime: python2.7
      Timeout: '60'
      Role:  !GetAtt [rLambdaExecutionRole, Arn]
  rPricingFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          from __future__ import print_function
          import json
          import decimal
          import boto3
          import os
          import pprint
          import cfnresponse
          def lambda_handler(event, context):
              pricing = boto3.client('pricing')
              responseData = {}
              if event['RequestType'] == 'Delete':
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              else:
                response = pricing.get_products(ServiceCode='AmazonEC2',Filters = [{'Type' :'TERM_MATCH', 'Field':'instanceType', 'Value':os.environ['instanceType']},{'Type' :'TERM_MATCH', 'Field':'location','Value':'US East (N. Virginia)'},{'Type' :'TERM_MATCH', 'Field':'preInstalledSw','Value':'NA'}, {'Type' :'TERM_MATCH', 'Field':'tenancy',  'Value':'Shared'},{'Type' :'TERM_MATCH', 'Field':'operatingSystem',  'Value':'Linux'}, {'Type' :'TERM_MATCH', 'Field':'operation',  'Value':'RunInstances'},{'Type' :'TERM_MATCH', 'Field':'capacitystatus',  'Value':'UnusedCapacityReservation'}],MaxResults=100)
                price = response['PriceList'][0]
                data = json.loads(price)
                for key, value in data['terms']['OnDemand'].items():
                    rateCode = key+'.6YS6EN2CT7'
                    responseData['price'] = "{0:.3f}".format(decimal.Decimal(data['terms']['OnDemand'][key]['priceDimensions'][rateCode]['pricePerUnit']['USD']))
                    cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
                return 'Completed with status {}'.format(responseData['price'])
      Handler: index.lambda_handler
      Environment:
        Variables:
          instanceType: !Ref pCoreInstanceType
      Runtime: python2.7
      Timeout: '60'
      Role: !GetAtt [rLambdaExecutionRole, Arn]
  rSecurityConfiguration:
    DependsOn: CertsInfo
    Type: 'AWS::EMR::SecurityConfiguration'
    Properties:
      SecurityConfiguration:
        EncryptionConfiguration:
          EnableInTransitEncryption: true
          EnableAtRestEncryption: true
          InTransitEncryptionConfiguration:
            TLSCertificateConfiguration:
              CertificateProviderType: PEM
              S3Object: !Join ['', ['s3://', !Ref 'pS3EMRBucketName', '/', !GetAtt CertsInfo.certskey]]
          AtRestEncryptionConfiguration:
            S3EncryptionConfiguration:
              EncryptionMode: SSE-S3
            LocalDiskEncryptionConfiguration:
              EncryptionKeyProviderType: AwsKms
              AwsKmsKey: !GetAtt 'pKMSLUKSKey.Arn'
  rEMRCluster:
    Properties:
      #"Fn::ImportValue" : {"Fn::Sub" : "SquidPrivateDNS${pClient}${pEnvironment}"
      #{"Fn::ImportValue" : {"Fn::Sub" : "SquidPrivateDNS${pClient}${pEnvironment}"}}
      AdditionalInfo: {'instanceAwsClientConfiguration' : {'proxyPort' : {"Fn::ImportValue" : {"Fn::Sub" : "SquidPort${pClient}${pEnvironment}"}}, 'proxyHost' : {"Fn::ImportValue" : {"Fn::Sub" : "SquidPrivateDNS${pClient}${pEnvironment}"}}} }
      SecurityConfiguration: !Ref rSecurityConfiguration
      Applications:
      - Name: Hive
      - Name: Spark
      - Name: Hue
#      - Name: HBase
#      - Name: Zookeeper
      - Name: !If [OlderVersion, 'Oozie-Sandbox', 'Oozie']
#account-review-HIVE-Integration
#{
#    "Classification": "hive-site",
#    "Properties": {
#      "hive.fetch.task.conversion": "minimal",
#      "hive.metastore.rawstore.impl": "com.cerebro.hive.metastore.CerebroObjectStore",
#      "hive.exec.pre.hooks": "com.okera.recordservice.hive.SetTokenPreExecute",
#      "recordservice.planner.hostports": "odas-planner-1.internal.net:12050"
#    }
#  }
      Configurations:
#      - Classification: hive-site
#        ConfigurationProperties:
#          javax.jdo.option.ConnectionURL:
#            Fn::Join:
#            - ''
#            - - jdbc:mysql://
#              - !ImportValue HiveMetastoreHost
#              - ":"
#              - !ImportValue HiveMetastorePort
#              - "/"
#              - hive?createDatabaseIfNotExist=true
#          javax.jdo.option.ConnectionUserName: !ImportValue HiveMetastoreDBUsername
#          javax.jdo.option.ConnectionPassword: !FindInMap [ Config, Hive, DevMetastorePassword ]
#        Configurations: []
      - Classification: hadoop-env
        Configurations:
          - Classification: "export"
            Configurations: []
            ConfigurationProperties:
              JAVA_HOME: /usr/lib/jvm/java-1.8.0
              HADOOP_DATANODE_HEAPSIZE: 8192
    #TEMP FOR DEMO - DELETE AND MASK RDS
#      - Classification: hive-site
#        ConfigurationProperties:
#          javax.jdo.option.ConnectionURL: "jdbc:mysql://expn-cis-amex-rds-hive-metadata.ciarbj0i7ybf.us-east-1.rds.amazonaws.com:3306/hmetadb?createDatabaseIfNotExist=true"
#          javax.jdo.option.ConnectionUserName: "msadmin"
#          javax.jdo.option.ConnectionPassword: "Experian.007"
#          datanucleus.autoCreateSchema: "false"
#        Configurations: []
      - Classification: spark-env
        Configurations:
          - Classification: "export"
            Configurations: []
            ConfigurationProperties:
              JAVA_HOME: /usr/lib/jvm/java-1.8.0
      - Classification: hadoop-kms-env
        Configurations:
          - Classification: "export"
            Configurations: []
            ConfigurationProperties:
              JAVA_HOME: /usr/lib/jvm/java-1.8.0
      - Classification: emrfs-site
        ConfigurationProperties:
          fs.s3.consistent: "true"
          fs.s3.consistent.metadata.read.capacity: "600"
          fs.s3.consistent.metadata.write.capacity: "300"
        Configurations: []
      BootstrapActions:
        - Name: DownloadScripts
          ScriptBootstrapAction:
            Args:
              - !Join ['', ['s3://', !Ref pS3EMRBucketName]]
              - us-east-1
              - !Join ['/', ['s3:/', !Ref pS3EMRBucketName, !Ref pExperianLANid, !Ref pS3StepsPath]]
            Path: !Join ['', ['s3://', !Ref pS3EMRBucketName, '/', !Ref pS3BAPath]]
#        - Name: UpdateCloudWatchProxy
#          ScriptBootstrapAction:
#            Args:
#              - !Join ['', ['s3://', !Ref pS3EMRBucketName]]
#              - us-east-1
#              - Fn::ImportValue: !Sub "SquidDNS${pClient}${pEnvironment}"
#              - Fn::ImportValue: !Sub "SquidPort${pClient}${pEnvironment}"
#            Path: !Join ['', ['s3://', !Ref pS3EMRBucketName, '/', admin/bootstrap/, 'update-cloudwatch.sh']]
#        - Name: DownloadPythonModules
#          ScriptBootstrapAction:
#            Args:
#              - us-east-1
#              - ip-172-16-0-48.ec2.internal
#              - 3128
#            Path: !Join ['', ['s3://', !Ref pS3EMRBucketName, '/', !Ref pS3PythonBootStrap]]
      Instances:
        AdditionalMasterSecurityGroups:
          - Fn::ImportValue: !Sub "EMRDefaultsg${pClient}${pEnvironment}"
          - !If [DoNoTerminate, 'Fn::ImportValue':  !Sub "EMRSSHsg${pClient}${pEnvironment}", !Ref 'AWS::NoValue']
        AdditionalSlaveSecurityGroups:
          - Fn::ImportValue: !Sub "EMRDefaultsg${pClient}${pEnvironment}"
          - !If [DoNoTerminate, 'Fn::ImportValue':  !Sub "EMRSSHsg${pClient}${pEnvironment}", !Ref 'AWS::NoValue']
        CoreInstanceGroup:
          EbsConfiguration:
            EbsBlockDeviceConfigs:
            - VolumeSpecification:
                SizeInGB: !Ref 'pCoreStorageVolume'
                VolumeType: gp2
              VolumesPerInstance: '1'
            EbsOptimized: 'true'
          InstanceCount: !Ref 'pCoreInstanceCount'
          InstanceType: !Ref 'pCoreInstanceType'
          Market: !If [UseSpot, SPOT, ON_DEMAND]
          BidPrice: !If [UseSpot, !GetAtt PricingInfo.price, !Ref 'AWS::NoValue']
          Name: Core Instance
        Ec2KeyName: !If [DoNoTerminate, !Ref 'pKeyName', !Ref 'AWS::NoValue']
        Ec2SubnetId: !Ref pSubnet
        MasterInstanceGroup:
          InstanceCount: '1'
          InstanceType: !Ref 'pMasterInstanceType'
          Market: ON_DEMAND
          Name: Master Instance
        TerminationProtected: 'false'
      JobFlowRole: !Join ['', ['EMR_EC2_DefaultRole', !Ref 'pClient' , !Ref 'pEnvironment']]
      CustomAmiId: !Ref 'pAmiID'
      LogUri: !Join ['/', ['s3:/', !Ref 'pS3EMRBucketName', !Ref 'pExperianLANid', !Ref 'pEMRLogDir']]
      Name: !Join ['-', ['EMR', !Ref 'pProject', !Ref 'pEnvironment', !Ref 'pExperianLANid', !If [DoNoTerminate, 'no-terminate', 'auto-terminate']]]
      ReleaseLabel: !Ref 'pEmrReleaseLabel'
      ServiceRole: EMR_DefaultRole
      Tags:
      - Key: Name
        Value: !Join ['-', ['EMR-Cluster', !Ref pClient, !Ref pEnvironment]]
      - Key: Team
        Value: !Ref 'pTeamTag'
      - Key: Client
        Value: !Ref 'pClient'
      - Key: Project
        Value: !Ref 'pProject'
      - Key: Environment
        Value: !Ref 'pEnvironment'
      - Key: Owner
        Value: !Ref 'pExperianLANid'
      - Key: Purpose
        Value: !Ref 'pPurpose'
      - Key: Application
        Value: !Ref 'pApplication'
      VisibleToAllUsers: 'true'
    Type: AWS::EMR::Cluster
#  SparkStep:
#    Properties:
#      ActionOnFailure: CONTINUE
#      HadoopJarStep:
#        Args:
#        - spark-submit
#        - --deploy-mode
#        - cluster
#        - --class
#        - org.apache.spark.examples.SparkPi
#        - /usr/lib/spark/examples/jars/spark-examples.jar
#        - '10'
#        Jar: command-runner.jar
#        MainClass: ''
#      JobFlowId: !Ref 'rEMRCluster'
#      Name: SparkStep
#    Type: AWS::EMR::Step
#  EMRSampleScriptRunner:
#    Properties:
#      ActionOnFailure: CONTINUE
#      HadoopJarStep:
#        Args:
#        - s3://cis-us-emr/admin/steps/emr-scipt-runner.sh
#        Jar: s3://cis-us-emr/admin/steps/script-runner.jar
#        MainClass: ''
#      JobFlowId: !Ref 'rEMRCluster'
#      Name: EMRSampleScriptRunner
#    Type: AWS::EMR::Step
#  DoNoTerminate:
#    Properties:
#      ActionOnFailure: CONTINUE
#      HadoopJarStep:
#        Args:
#        - aws
#        - emr
#        - terminate-clusters
#        - --cluster-ids
#        - !Ref rEMRCluster
#        Jar: command-runner.jar
#        MainClass: ''
#      JobFlowId: !Ref 'rEMRCluster'
#      Name: DoNoTerminate
#    Type: AWS::EMR::Step
  RunSteps:
    Condition: Terminate
    Properties:
      ActionOnFailure: CONTINUE
      HadoopJarStep:
        Args:
        - /tmp/emrsteps/update-emr-steps.sh
        - !Ref rEMRCluster
        - !Ref 'AWS::StackName'
        - Fn::ImportValue: !Sub "SquidPrivateDNS${pClient}${pEnvironment}"
#        - !ImportValue SquidPrivateDNSsynchronyprod
        - Fn::ImportValue: !Sub "SquidPort${pClient}${pEnvironment}"
#        - !ImportValue SquidPortsynchronyprod
        - us-east-1
        Jar: command-runner.jar
        MainClass: ''
      JobFlowId: !Ref 'rEMRCluster'
      Name: RunSteps
    Type: AWS::EMR::Step 